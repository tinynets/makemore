{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '.', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z'}\n"
     ]
    }
   ],
   "source": [
    "# build hr vocab of charactersandmappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))   \n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the dataset\n",
    "\n",
    "block_size = 3\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        # print(''.join([itos[i] for i in context]), '--->', itos[ix])\n",
    "        context = context[1:] + [ix]\n",
    "\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27, 2), generator=g)\n",
    "W1 = torch.randn((6, 100), generator=g)\n",
    "b1 = torch.randn(100, generator=g)\n",
    "W2 = torch.randn((100, 27), generator=g)\n",
    "b2 = torch.randn(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3481\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3691954612731934\n",
      "2.9099276065826416\n",
      "2.112687110900879\n",
      "2.653762102127075\n",
      "2.891634225845337\n",
      "2.188856840133667\n",
      "2.711789846420288\n",
      "2.416246175765991\n",
      "2.073697328567505\n",
      "2.641990900039673\n",
      "2.3897008895874023\n",
      "2.2222719192504883\n",
      "2.378560781478882\n",
      "2.243832588195801\n",
      "2.863234758377075\n",
      "2.4920461177825928\n",
      "2.9885661602020264\n",
      "2.65461802482605\n",
      "2.509366989135742\n",
      "2.546501398086548\n",
      "2.3439981937408447\n",
      "2.411078453063965\n",
      "2.2023608684539795\n",
      "2.3983614444732666\n",
      "2.0666842460632324\n",
      "2.2146198749542236\n",
      "3.1297576427459717\n",
      "2.64968204498291\n",
      "2.4706151485443115\n",
      "2.5774712562561035\n",
      "2.682732582092285\n",
      "2.315634250640869\n",
      "2.1759328842163086\n",
      "2.331610918045044\n",
      "2.3621528148651123\n",
      "2.7122483253479004\n",
      "2.4999375343322754\n",
      "3.1129531860351562\n",
      "2.4066853523254395\n",
      "2.404245138168335\n",
      "2.157064199447632\n",
      "2.0063774585723877\n",
      "2.4333345890045166\n",
      "2.527406692504883\n",
      "2.3567981719970703\n",
      "2.6762256622314453\n",
      "2.6340646743774414\n",
      "2.535440683364868\n",
      "2.434802770614624\n",
      "2.480407238006592\n",
      "2.5462303161621094\n",
      "2.015171527862549\n",
      "2.6523659229278564\n",
      "2.654015064239502\n",
      "2.4916486740112305\n",
      "2.696453332901001\n",
      "2.1128435134887695\n",
      "2.7860214710235596\n",
      "2.108290195465088\n",
      "2.3683972358703613\n",
      "2.4809634685516357\n",
      "2.615591287612915\n",
      "2.448671579360962\n",
      "2.9253244400024414\n",
      "2.325148105621338\n",
      "2.1106629371643066\n",
      "2.422348737716675\n",
      "2.374528646469116\n",
      "2.48118257522583\n",
      "2.485684871673584\n",
      "2.377133846282959\n",
      "2.4590871334075928\n",
      "2.239443302154541\n",
      "2.5147838592529297\n",
      "2.1731295585632324\n",
      "2.3610401153564453\n",
      "2.509326696395874\n",
      "2.380990505218506\n",
      "2.7378172874450684\n",
      "2.707998037338257\n",
      "2.3787617683410645\n",
      "2.6516776084899902\n",
      "2.0129334926605225\n",
      "2.3623852729797363\n",
      "2.194838762283325\n",
      "2.3626413345336914\n",
      "2.4930338859558105\n",
      "2.399322032928467\n",
      "2.469146490097046\n",
      "2.2659616470336914\n",
      "2.8924875259399414\n",
      "3.1985678672790527\n",
      "2.298007011413574\n",
      "2.553051471710205\n",
      "3.0672123432159424\n",
      "2.554581642150879\n",
      "2.961974620819092\n",
      "2.742902994155884\n",
      "2.6789252758026123\n",
      "2.6900949478149414\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, X.shape[0], (32,))\n",
    "\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[X[ix]] # (32, 3, 2)\n",
    "    h = torch.tanh(emb.view(-1, 6) @ W1 + b1) # (32, 100)\n",
    "    logits = h @ W2 + b2 # (32, 27)\n",
    "    loss = F.cross_entropy(logits, Y[ix])\n",
    "    \n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "    #update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([133484,  94788, 114358, 141683, 111286,  93049,  65770,   7480, 187921,\n",
       "        153476,  64192,  43697, 133952,  10552,  89086, 166542,  83006,  82803,\n",
       "         14094, 174110,  24291,  52362, 123879, 164543,   5667,  58433, 209722,\n",
       "        203952,  24106, 158902, 121734,  43743])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0, X.shape[0], (32, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
